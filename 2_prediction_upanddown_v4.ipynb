{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifications:\n",
    "\n",
    "1. Turn different models into another file, and VWAP should import the models to read models.\n",
    "2. Rewrite VWAP LSTM factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir=\"./data/\"\n",
    "ticker=\"TSLA\"\n",
    "\n",
    "date_pool=pd.date_range(\"1/1/2019\",\"1/31/2019\",freq=\"B\").strftime(\"%Y%m%d\")\n",
    "date_pool=[d for d in date_pool if os.path.exists(data_dir+\"trades_{}_{}.csv\".format(d,ticker))]\n",
    "\n",
    "train_days=10\n",
    "train_date_list=date_pool[:train_days]\n",
    "test_date_list=date_pool[train_days+1:]\n",
    "time_steps = 50\n",
    "\n",
    "nforward=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline():\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.scaler = None\n",
    "    def load_data(self, ticker, date):\n",
    "        df = pd.read_csv(data_dir+'trades_{}_{}.csv'.format(date, ticker),index_col=[0],parse_dates=[0])\n",
    "\n",
    "        # Feature Engineering\n",
    "        df[\"direction\"]=(df[\"trade_px\"]-df[\"trade_px\"].shift(1)).apply(np.sign)\n",
    "        df[\"pct_change\"]=df[\"trade_px\"].pct_change()\n",
    "\n",
    "        mysign=lambda x: 0 if abs(x)<1e-5 else (1 if x>0 else -1)\n",
    "        df[\"label\"]=(df[\"trade_px\"].rolling(nforward).mean().shift(-nforward)-df[\"trade_px\"]).apply(mysign)\n",
    "        # df[\"label\"]=(df[\"trade_px\"].shift(-1)-df[\"trade_px\"]).apply(np.sign) # last version\n",
    "\n",
    "        df.fillna(method=\"ffill\",inplace=True)\n",
    "        df.dropna(axis=0,inplace=True)\n",
    "        # print(df.head(10),df.shape)\n",
    "        # print(\"NaN number: \",df.isna().sum().sum())\n",
    "\n",
    "        return df[[\"trade_px\",\"trade_size\",\"pct_change\",\"direction\",\"label\"]].values\n",
    "\n",
    "    def create_dataset(self, ticker=ticker, dates=train_date_list, time_steps = time_steps, input_scaler=None):  \n",
    "        for i,d in enumerate(dates):\n",
    "            datanew = self.load_data(ticker,d)\n",
    "            if i==0:\n",
    "                data=datanew\n",
    "            else:\n",
    "                data=np.vstack((data, datanew))\n",
    "\n",
    "        label=data[:,-1]\n",
    "        data=data[:,:-1]\n",
    "\n",
    "        if input_scaler is None:\n",
    "            scaler=StandardScaler()\n",
    "            data=scaler.fit_transform(data)\n",
    "        else:\n",
    "            data=input_scaler.transform(data)\n",
    "            scaler=input_scaler\n",
    "\n",
    "        x = [data[0 : time_steps]]\n",
    "        y = [label[time_steps-1]]\n",
    "        N=len(data)//time_steps\n",
    "\n",
    "        print(N)\n",
    "        for i in range(1, N):\n",
    "            t = data[i*time_steps: (i + 1)*time_steps]\n",
    "            x = np.vstack((x, [t]))\n",
    "            y.append(label[(i + 1)*time_steps-1])\n",
    "\n",
    "        y=pd.get_dummies(y)\n",
    "        #print(y)\n",
    "\n",
    "        return x,y.values,scaler\n",
    "\n",
    "    def loss_plot(self, history, plot_name = 'Loss'): # type(history) is dict\n",
    "        loss = np.asarray(history['loss'])\n",
    "        val_loss = np.asarray(history['val_loss'])\n",
    "\n",
    "        plt.style.use('seaborn')\n",
    "        plt.figure(figsize = (20,6), dpi=dpi)\n",
    "        plt.grid(True)\n",
    "        plt.plot(loss, color = 'darkgrey')\n",
    "        plt.plot(val_loss, color = 'tan')\n",
    "        plt.legend(['loss', 'val_loss'])\n",
    "        # plt.savefig('{}_{}_{}_{}_{}.png'.format(ticker, plot_name, str(n_epochs), str(time_steps), str(batch_size)))\n",
    "    \n",
    "    \n",
    "    def training_data_transform(self, ticker):\n",
    "        # Load train data\n",
    "        x, y, scaler = self.create_dataset(ticker)\n",
    "        self.x, self.y, self.scaler = x, y, scaler\n",
    "        print(\"Finished loading data.\")\n",
    "\n",
    "        with open(\"model/scaler_{}_{}.p\".format(train_date_list[0],train_date_list[-1]),\"wb\") as f:\n",
    "            pickle.dump(scaler,f)\n",
    "\n",
    "    def model_training_testing(self, ticker, model, plot = False):\n",
    "        # Model Training pipeline\n",
    "        model_functionalities = Model_Functionalities(model)\n",
    "        \n",
    "        x, y, scaler = self.x, self.y, self.scaler\n",
    "        print(y[:10])\n",
    "        \n",
    "        if x is None:\n",
    "            print(\"None Training data processed\")\n",
    "            return\n",
    "        \n",
    "        # Build model, in-sample train test\n",
    "        train_history = model_functionalities.train_test(x, y, plot)  \n",
    "        if model_functionalities.model.model_name == \"LSTM\":\n",
    "            if plot == True:\n",
    "                self.loss_plot(train_history.history)\n",
    "\n",
    "        with open(\"model/\" + model.model_name + \"_{}_{}.p\".format(train_date_list[0],train_date_list[-1]),\"wb\") as f:\n",
    "            pickle.dump(model_functionalities.model,f)\n",
    "\n",
    "        # Out-of-sample test\n",
    "        for test_date in test_date_list:\n",
    "            # create test dateset\n",
    "            x_test, y_test, _ = self.create_dataset(ticker=ticker, dates=[test_date], time_steps = time_steps, input_scaler=scaler)\n",
    "            x_test, y_test = model_functionalities.model.reshape_dataset(x_test, y_test)\n",
    "\n",
    "            # use precious trained model to test\n",
    "            y_test_pred = model_functionalities.predict(x_test)\n",
    "            if model_functionalities.model.model_name == \"LSTM\":\n",
    "                if plot == True:\n",
    "                    model_functionalities.view_accuracy(y_test_pred.argmax(axis=1), y_test.argmax(axis=1))\n",
    "            if y_test.shape[1] != 1:\n",
    "                accuracy = np.mean(y_test_pred.argmax(axis=1)==y_test.argmax(axis=1))\n",
    "            else:\n",
    "                accuracy = np.mean(y_test_pred==y_test)\n",
    "            print(test_date+\" accuracy: \", accuracy)\n",
    "        return model_functionalities.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Functionalities():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    def train_test(self, x, y, plot = False):\n",
    "        \n",
    "        size = len(x)\n",
    "        if size!=len(y):\n",
    "            return None\n",
    "        x = x[: batch_size * (size // batch_size)]\n",
    "        y = y[: batch_size * (size // batch_size)]\n",
    "        \n",
    "        x, y = self.model.reshape_dataset(x, y)\n",
    "\n",
    "        x_train, x_validation, y_train, y_validation= train_test_split(x, y, test_size = 0.1, shuffle = True)\n",
    "        print('train', x_train.shape, y_train.shape)\n",
    "        print('validation', x_validation.shape, y_validation.shape)\n",
    "        \n",
    "        \n",
    "        if self.model.model_name == \"LSTM\" or  self.model.model_name == \"CNN\":\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=stop_patience, mode=\"min\", verbose=2, restore_best_weights=True)\n",
    "            history = self.model.fit(x_train, y_train, batch_size = batch_size, epochs = n_epochs,\n",
    "                                     validation_data=(x_validation, y_validation),callbacks=[early_stopping])\n",
    "        else:\n",
    "            self.model.fit(x_train, y_train)\n",
    "        \n",
    "        self.y_pred = self.model.predict(x_validation)\n",
    "        self.y_validation_true = y_validation\n",
    "        \n",
    "        if plot == True:\n",
    "            if y.shape[1] != 1:\n",
    "                self.train_plot = self.view_accuracy(self.predict(x_train).argmax(axis=1), y_train.argmax(axis=1), 'Train')\n",
    "                self.validation_plot = self.view_accuracy(self.predict(x_validation).argmax(axis=1), y_validation.argmax(axis=1), 'Validation')\n",
    "            else:\n",
    "                self.train_plot = self.view_accuracy(self.predict(x_train), y_train, 'Train')\n",
    "                self.validation_plot = self.view_accuracy(self.predict(x_validation), y_validation, 'Validation')\n",
    "        if self.model.model_name == \"LSTM\":\n",
    "            return history\n",
    "\n",
    "    def predict(self, x_validation):\n",
    "        pred = self.model.predict(x_validation)\n",
    "        return pred\n",
    "    \n",
    "    def view_accuracy(self, y_pred = None, y_true = None, plot_name = 'Test', num=100):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.y_pred.argmax(axis=1)\n",
    "            y_true = self.y_validation_true.argmax(axis=1)\n",
    "        \n",
    "        plt.style.use('seaborn')\n",
    "        plt.figure(figsize = (20,6), dpi=dpi)\n",
    "        plt.grid(True)\n",
    "        plt.plot(y_pred[:num], color = 'lightcoral')\n",
    "        plt.plot(y_true[:num], color = 'cornflowerblue', linewidth = 1)\n",
    "        plt.title('{}_{}'.format(ticker, plot_name))\n",
    "        plt.legend(['predict', 'true'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15154\n",
      "Finished loading data.\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline()\n",
    "pipeline.training_data_transform(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 0.4747261449122344\n",
      "neutral 0.03932954995380757\n",
      "negative 0.48594430513395803\n"
     ]
    }
   ],
   "source": [
    "labels = pipeline.y.argmax(axis = 1) - 1\n",
    "print(\"positive\", (labels == 1).mean())\n",
    "print(\"neutral\", (labels == 0).mean())\n",
    "print(\"negative\", (labels == -1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTM to predict next up and down\n",
    "## v2: Predict up and downs of the average of $\\mathbf{nforward}=10$ following prices\n",
    "\n",
    "1. Too slow to predict (next trade may happen in millisecond)\n",
    "2. Only classification of up, down and same. No quantitative prediction (can be improved to predict quantity of price movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 30\n",
    "n_epochs = 100\n",
    "batch_size = 128\n",
    "activation = \"tanh\"\n",
    "loss = 'categorical_crossentropy'\n",
    "stop_patience=20\n",
    "\n",
    "dpi=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 20:37:59.046767: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "train (13593, 50, 4) (13593, 3)\n",
      "validation (1511, 50, 4) (1511, 3)\n",
      "Epoch 1/100\n",
      "107/107 [==============================] - 7s 41ms/step - loss: 0.8709 - accuracy: 0.4944 - val_loss: 0.8082 - val_accuracy: 0.5539\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 4s 33ms/step - loss: 0.8088 - accuracy: 0.5569 - val_loss: 0.7743 - val_accuracy: 0.5652\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 4s 37ms/step - loss: 0.7712 - accuracy: 0.5779 - val_loss: 0.7520 - val_accuracy: 0.5665\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7566 - accuracy: 0.5861 - val_loss: 0.7412 - val_accuracy: 0.5745\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7491 - accuracy: 0.5855 - val_loss: 0.7347 - val_accuracy: 0.5831\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7461 - accuracy: 0.5882 - val_loss: 0.7418 - val_accuracy: 0.5784\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7416 - accuracy: 0.5919 - val_loss: 0.7356 - val_accuracy: 0.5831\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7392 - accuracy: 0.5914 - val_loss: 0.7346 - val_accuracy: 0.5831\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7386 - accuracy: 0.5951 - val_loss: 0.7349 - val_accuracy: 0.5778\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7362 - accuracy: 0.5959 - val_loss: 0.7275 - val_accuracy: 0.5725\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7355 - accuracy: 0.5960 - val_loss: 0.7290 - val_accuracy: 0.5804\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7337 - accuracy: 0.5957 - val_loss: 0.7277 - val_accuracy: 0.5797\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7335 - accuracy: 0.5952 - val_loss: 0.7292 - val_accuracy: 0.5797\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7316 - accuracy: 0.5988 - val_loss: 0.7287 - val_accuracy: 0.5764\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 4s 37ms/step - loss: 0.7308 - accuracy: 0.5985 - val_loss: 0.7260 - val_accuracy: 0.5797\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7320 - accuracy: 0.5980 - val_loss: 0.7287 - val_accuracy: 0.5811\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7300 - accuracy: 0.5994 - val_loss: 0.7290 - val_accuracy: 0.5864\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 4s 37ms/step - loss: 0.7303 - accuracy: 0.5981 - val_loss: 0.7272 - val_accuracy: 0.5771\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 4s 37ms/step - loss: 0.7292 - accuracy: 0.5979 - val_loss: 0.7275 - val_accuracy: 0.5771\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7286 - accuracy: 0.6016 - val_loss: 0.7284 - val_accuracy: 0.5864\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7274 - accuracy: 0.6003 - val_loss: 0.7280 - val_accuracy: 0.5804\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7277 - accuracy: 0.6018 - val_loss: 0.7263 - val_accuracy: 0.5791\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 4s 40ms/step - loss: 0.7271 - accuracy: 0.6049 - val_loss: 0.7270 - val_accuracy: 0.5903\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7262 - accuracy: 0.5985 - val_loss: 0.7268 - val_accuracy: 0.5837\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7249 - accuracy: 0.6033 - val_loss: 0.7277 - val_accuracy: 0.5831\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7247 - accuracy: 0.6013 - val_loss: 0.7260 - val_accuracy: 0.5831\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7240 - accuracy: 0.6061 - val_loss: 0.7272 - val_accuracy: 0.5917\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7232 - accuracy: 0.6030 - val_loss: 0.7287 - val_accuracy: 0.5844\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7221 - accuracy: 0.6052 - val_loss: 0.7344 - val_accuracy: 0.5870\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7228 - accuracy: 0.6049 - val_loss: 0.7254 - val_accuracy: 0.5884\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7214 - accuracy: 0.6056 - val_loss: 0.7257 - val_accuracy: 0.5943\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7206 - accuracy: 0.6076 - val_loss: 0.7297 - val_accuracy: 0.5910\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7190 - accuracy: 0.6032 - val_loss: 0.7254 - val_accuracy: 0.5864\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7182 - accuracy: 0.6085 - val_loss: 0.7279 - val_accuracy: 0.5884\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7174 - accuracy: 0.6072 - val_loss: 0.7260 - val_accuracy: 0.5824\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7167 - accuracy: 0.6081 - val_loss: 0.7331 - val_accuracy: 0.5976\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 4s 36ms/step - loss: 0.7157 - accuracy: 0.6131 - val_loss: 0.7272 - val_accuracy: 0.5923\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7141 - accuracy: 0.6112 - val_loss: 0.7301 - val_accuracy: 0.5758\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7124 - accuracy: 0.6156 - val_loss: 0.7301 - val_accuracy: 0.5877\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 4s 37ms/step - loss: 0.7112 - accuracy: 0.6152 - val_loss: 0.7333 - val_accuracy: 0.5903\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7107 - accuracy: 0.6164 - val_loss: 0.7277 - val_accuracy: 0.5983\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7097 - accuracy: 0.6158 - val_loss: 0.7336 - val_accuracy: 0.5850\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7082 - accuracy: 0.6155 - val_loss: 0.7320 - val_accuracy: 0.5864\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7053 - accuracy: 0.6218 - val_loss: 0.7368 - val_accuracy: 0.5817\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.7037 - accuracy: 0.6210 - val_loss: 0.7322 - val_accuracy: 0.5923\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7022 - accuracy: 0.6250 - val_loss: 0.7405 - val_accuracy: 0.5910\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 4s 34ms/step - loss: 0.7013 - accuracy: 0.6253 - val_loss: 0.7375 - val_accuracy: 0.5811\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.6987 - accuracy: 0.6266 - val_loss: 0.7404 - val_accuracy: 0.5956\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.6971 - accuracy: 0.6285 - val_loss: 0.7395 - val_accuracy: 0.5963\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.6294Restoring model weights from the end of the best epoch: 30.\n",
      "107/107 [==============================] - 4s 35ms/step - loss: 0.6942 - accuracy: 0.6294 - val_loss: 0.7404 - val_accuracy: 0.6029\n",
      "Epoch 00050: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 20:41:14.914006: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7325c593-ca58-49a0-8f9a-2b056f4b0ef0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7325c593-ca58-49a0-8f9a-2b056f4b0ef0/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fc16f43c990> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fc16f633dd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n",
      "20190117 accuracy:  0.5866336633663366\n",
      "5342\n",
      "20190118 accuracy:  0.6233620366903782\n",
      "2570\n",
      "20190122 accuracy:  0.6105058365758755\n",
      "2944\n",
      "20190123 accuracy:  0.6192255434782609\n",
      "1759\n",
      "20190124 accuracy:  0.5929505400795907\n",
      "1610\n",
      "20190125 accuracy:  0.6018633540372671\n",
      "1428\n",
      "20190128 accuracy:  0.5756302521008403\n",
      "1034\n",
      "20190129 accuracy:  0.5899419729206963\n",
      "2164\n",
      "20190130 accuracy:  0.5804066543438078\n",
      "2679\n",
      "20190131 accuracy:  0.6091825307950728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.LSTM_Model at 0x7fc16f43c910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = LSTM_Model(time_steps = time_steps,  hidden_dim = hidden_dim, n_epochs = n_epochs,\n",
    "                        activation = activation, loss = loss, \n",
    "                        data_dim = pipeline.x.shape[-1], output_dim = pipeline.y.shape[-1])\n",
    "lstm_model.build()\n",
    "pipeline.model_training_testing(ticker, lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15154, 50, 4) (15154, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.x.shape, pipeline.y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 30\n",
    "n_epochs = 100\n",
    "batch_size = 128\n",
    "activation = \"relu\"\n",
    "loss = 'categorical_crossentropy'\n",
    "stop_patience=20\n",
    "\n",
    "dpi=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "train (13593, 50, 4, 1) (13593, 3)\n",
      "validation (1511, 50, 4, 1) (1511, 3)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xunyingluo/opt/anaconda3/envs/py37/lib/python3.7/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 1s 8ms/step - loss: 0.8537 - accuracy: 0.4967 - val_loss: 0.8366 - val_accuracy: 0.5308\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.8024 - accuracy: 0.5499 - val_loss: 0.8359 - val_accuracy: 0.5433\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7820 - accuracy: 0.5729 - val_loss: 0.8084 - val_accuracy: 0.5718\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7671 - accuracy: 0.5857 - val_loss: 0.7974 - val_accuracy: 0.5824\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7576 - accuracy: 0.5930 - val_loss: 0.7963 - val_accuracy: 0.5745\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7519 - accuracy: 0.5918 - val_loss: 0.8072 - val_accuracy: 0.5824\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7437 - accuracy: 0.5971 - val_loss: 0.8026 - val_accuracy: 0.5811\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7416 - accuracy: 0.6016 - val_loss: 0.8064 - val_accuracy: 0.5844\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7403 - accuracy: 0.5985 - val_loss: 0.8035 - val_accuracy: 0.5758\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7384 - accuracy: 0.6019 - val_loss: 0.8087 - val_accuracy: 0.5831\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7355 - accuracy: 0.6068 - val_loss: 0.8023 - val_accuracy: 0.5797\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7329 - accuracy: 0.6084 - val_loss: 0.8078 - val_accuracy: 0.5778\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7312 - accuracy: 0.6122 - val_loss: 0.8207 - val_accuracy: 0.5850\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7304 - accuracy: 0.6113 - val_loss: 0.8140 - val_accuracy: 0.5831\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7278 - accuracy: 0.6164 - val_loss: 0.8212 - val_accuracy: 0.5771\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7303 - accuracy: 0.6141 - val_loss: 0.8168 - val_accuracy: 0.5884\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.7258 - accuracy: 0.6183 - val_loss: 0.8188 - val_accuracy: 0.5784\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 0.7251 - accuracy: 0.6158 - val_loss: 0.8270 - val_accuracy: 0.5764\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.7213 - accuracy: 0.6230 - val_loss: 0.8366 - val_accuracy: 0.5890\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.7224 - accuracy: 0.6200 - val_loss: 0.8380 - val_accuracy: 0.5758\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7216 - accuracy: 0.6246 - val_loss: 0.8296 - val_accuracy: 0.5685\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7228 - accuracy: 0.6166 - val_loss: 0.8340 - val_accuracy: 0.5791\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.7194 - accuracy: 0.6219 - val_loss: 0.8306 - val_accuracy: 0.5850\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.7187 - accuracy: 0.6253 - val_loss: 0.8395 - val_accuracy: 0.5685\n",
      "Epoch 25/100\n",
      " 98/107 [==========================>...] - ETA: 0s - loss: 0.7167 - accuracy: 0.6232Restoring model weights from the end of the best epoch: 5.\n",
      "107/107 [==============================] - 1s 7ms/step - loss: 0.7179 - accuracy: 0.6227 - val_loss: 0.8320 - val_accuracy: 0.5665\n",
      "Epoch 00025: early stopping\n",
      "INFO:tensorflow:Assets written to: ram://9aa3d75b-ef21-4948-a8a4-598865c3e658/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9aa3d75b-ef21-4948-a8a4-598865c3e658/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808\n",
      "20190117 accuracy:  0.5321782178217822\n",
      "5342\n",
      "20190118 accuracy:  0.6044552602021714\n",
      "2570\n",
      "20190122 accuracy:  0.6054474708171206\n",
      "2944\n",
      "20190123 accuracy:  0.5920516304347826\n",
      "1759\n",
      "20190124 accuracy:  0.5787379192723138\n",
      "1610\n",
      "20190125 accuracy:  0.6\n",
      "1428\n",
      "20190128 accuracy:  0.5833333333333334\n",
      "1034\n",
      "20190129 accuracy:  0.5802707930367504\n",
      "2164\n",
      "20190130 accuracy:  0.5794824399260629\n",
      "2679\n",
      "20190131 accuracy:  0.5871593878312803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.CNN_Model at 0x7fc1846a4190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = CNN_Model(time_steps = time_steps, hidden_dim = hidden_dim, n_epochs=n_epochs,\n",
    "                      activation = activation, loss = loss,\n",
    "                      data_dim = pipeline.x.shape[-1], output_dim = pipeline.y.shape[-1])\n",
    "cnn_model.build()\n",
    "pipeline.model_training_testing(ticker, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=36\n",
    "n_estimators=100\n",
    "max_features=0.2\n",
    "criterion = 'gini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "train (13593, 200) (13593, 3)\n",
      "validation (1511, 200) (1511, 3)\n",
      "808\n",
      "20190117 accuracy:  0.5606435643564357\n",
      "5342\n",
      "20190118 accuracy:  0.5883564208161737\n",
      "2570\n",
      "20190122 accuracy:  0.5649805447470817\n",
      "2944\n",
      "20190123 accuracy:  0.5360054347826086\n",
      "1759\n",
      "20190124 accuracy:  0.5139283683911313\n",
      "1610\n",
      "20190125 accuracy:  0.5515527950310559\n",
      "1428\n",
      "20190128 accuracy:  0.5532212885154062\n",
      "1034\n",
      "20190129 accuracy:  0.5773694390715667\n",
      "2164\n",
      "20190130 accuracy:  0.5688539741219963\n",
      "2679\n",
      "20190131 accuracy:  0.572601717058604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.RandomForest at 0x7fc170e1bf90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_model = RandomForest(max_depth, n_estimators, max_features, criterion)\n",
    "pipeline.model_training_testing(ticker, random_forest_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=500\n",
    "max_depth=10\n",
    "learning_rate=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "train (13593, 200) (13593, 1)\n",
      "validation (1511, 200) (1511, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xunyingluo/opt/anaconda3/envs/py37/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "gradient_boost_model=GradientBoost(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate)\n",
    "pipeline.model_training_testing(ticker, gradient_boost_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=500\n",
    "max_depth=10\n",
    "learning_rate=0.01\n",
    "reg_lambda=0.1\n",
    "verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model=XGBoost(n_estimators=n_estimators, max_depth=max_depth,learning_rate=learning_rate,reg_lambda=reg_lambda, verbose=verbose)\n",
    "pipeline.model_training_testing(ticker, xgboost_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tick Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TICK FACTOR\n",
    "# only update if it's a trade\n",
    "# if message_type == 't':\n",
    "#     # calc the tick\n",
    "#     this_tick = np.sign(last_price - prev_price)\n",
    "#     if this_tick == 0:\n",
    "#         this_tick = prev_tick\n",
    "\n",
    "#     # now calc the tick\n",
    "#     if tick_factor == 0:\n",
    "#         tick_factor = this_tick\n",
    "#     else:\n",
    "#         tick_factor = (tick_ema_alpha * this_tick) + (1 - tick_ema_alpha) * tick_factor\n",
    "\n",
    "#         # store the last tick\n",
    "#     prev_tick = this_tick\n",
    "\n",
    "for test_date in test_date_list:\n",
    "    df = pd.read_csv(data_dir+'trades_{}_{}.csv'.format(test_date, ticker),index_col=[0],parse_dates=[0])\n",
    "    \n",
    "    df[\"tick_test\"]=(df[\"trade_px\"]-df[\"trade_px\"].shift(1)).apply(lambda x: 1 if x>0. else (-1. if x<0 else np.nan))\n",
    "    df.fillna(method=\"ffill\",inplace=True)\n",
    "    \n",
    "    df[\"tick_factor\"]=df[\"tick_test\"].ewm(span=20).mean()\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    \n",
    "    mysign = lambda x: 0 if abs(x)<1e-5 else (1 if x>0 else -1)\n",
    "    df[\"predict\"]=df[\"tick_factor\"].apply(mysign)\n",
    "    df[\"real_movement\"]=(df[\"trade_px\"].rolling(nforward).mean().shift(-nforward)-df[\"trade_px\"]).apply(mysign)\n",
    "    \n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    acc=np.mean(df[\"predict\"]==df[\"real_movement\"])\n",
    "    print(\"Accuracy of {}\".format(test_date),acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum=pd.Timedelta(0)\n",
    "count=0\n",
    "for test_date in test_date_list:\n",
    "    df = pd.read_csv(data_dir+'trades_{}_{}.csv'.format(test_date, ticker),index_col=[0],parse_dates=[0])\n",
    "    timestamp=pd.DataFrame({\"trade_time\":df.index})\n",
    "    dt=timestamp[\"trade_time\"].shift(-nforward)-timestamp[\"trade_time\"]\n",
    "    dt.dropna(axis=0,inplace=True)\n",
    "    dt.apply(lambda x:x.seconds).hist()\n",
    "    sum+=dt.sum()\n",
    "    count+=dt.shape[0]\n",
    "print(\"Average time interval between {} trades is\".format(nforward),sum/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
